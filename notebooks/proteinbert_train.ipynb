{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e5a8ca-9eae-41a7-a1be-cde0d463b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ecf403a-9e4d-48a3-9673-9b35a73c1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import AdamW, SGD\n",
    "from collections import namedtuple\n",
    "\n",
    "import proteinbert_gen.constants as consts\n",
    "import proteinbert_gen.mask_diffusion as mask_diffusion\n",
    "\n",
    "from proteinbert_gen.debugging import print2\n",
    "from proteinbert_gen.proteinbert import ProteinBERT, load_pretrained_weights\n",
    "from proteinbert_gen.word_freq import create_word_freq_tensor\n",
    "from proteinbert_gen.tokenizer import ProteinTokenizer\n",
    "from proteinbert_gen.dataset import sprot_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe024125-8e53-4eed-817a-baff253eed73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmattfeng\u001b[0m (\u001b[33mkaiogenbio\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matt/proteinbert_gen/notebooks/wandb/run-20240514_090505-j436zcb0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kaiogenbio/proteinbert_gen/runs/j436zcb0' target=\"_blank\">cosmic-aardvark-54</a></strong> to <a href='https://wandb.ai/kaiogenbio/proteinbert_gen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kaiogenbio/proteinbert_gen' target=\"_blank\">https://wandb.ai/kaiogenbio/proteinbert_gen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kaiogenbio/proteinbert_gen/runs/j436zcb0' target=\"_blank\">https://wandb.ai/kaiogenbio/proteinbert_gen/runs/j436zcb0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hyperparameters = namedtuple(\n",
    "    \"Hyperparameters\",\n",
    "    [\n",
    "        \"batch_size\",\n",
    "        \"epochs\",\n",
    "        \"num_steps\",\n",
    "        \"word_freq_lambda\",\n",
    "        \"device\",\n",
    "        \"hybrid_lambda\",\n",
    "        \"lr\",\n",
    "        \"logging_steps\",\n",
    "        \"eval_step_size\",\n",
    "        \"clip_grad\",\n",
    "        \"clip_grad_val\",\n",
    "        \"warmup_scheduler\",\n",
    "        \"optimizer_cls\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "args = Hyperparameters(\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    num_steps=4096,\n",
    "    word_freq_lambda=0.3,\n",
    "    device=\"cuda\",\n",
    "    hybrid_lambda=1e-3,\n",
    "    lr=1e-3,\n",
    "    logging_steps=25,\n",
    "    eval_step_size=4,\n",
    "    clip_grad_val=10,\n",
    "    clip_grad=False,\n",
    "    warmup_scheduler=False,\n",
    "    optimizer_cls=AdamW\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"proteinbert_gen\",\n",
    "    config={k:str(v) for k, v in args._asdict().items()},\n",
    "    # mode=\"disabled\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "178e9acb-8320-4ef8-8f97-907446412932",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleClassBase(abc.ABC):\n",
    "    def sample(self, logits, x_0):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def post_process_sample_in_prediction(self, sample, x_0):\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Categorical(SampleClassBase):\n",
    "    def sample(self, logits, x_0):\n",
    "        return torch.distributions.categorical.Categorical(logits=logits).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae28cd3c-6a7d-4602-802f-bdba23dbc6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9930, 0.8760, 0.9626, 0.9751, 0.9424, 0.9824, 0.9082, 0.9710, 0.9673,\n",
       "        1.0000, 0.9151, 0.9418, 0.9518, 0.9393, 0.9652, 0.9708, 0.9611, 0.3411,\n",
       "        0.9802, 0.8615, 0.5221, 0.9240, 0.0000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_freq_preprocess_fn(wf):\n",
    "    wf = wf + 1\n",
    "    wf = wf.log()\n",
    "    wf = wf / wf.max()\n",
    "\n",
    "    # range: 0 - 1\n",
    "    return wf\n",
    "\n",
    "def process_fn_in_collate(wf):\n",
    "    return wf - wf.mean()\n",
    "\n",
    "\n",
    "tokenizer = ProteinTokenizer()\n",
    "wf_tensor = create_word_freq_tensor(\"../data/sprot_1m_word_freq_dict.pkl\", tokenizer.ALL_TOKENS)\n",
    "# wf_tensor[tokenizer.mask_token_id] = 0\n",
    "wf_tensor[tokenizer.pad_token_id] = 0\n",
    "wf_tensor = word_freq_preprocess_fn(wf_tensor)\n",
    "wf_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ddc04c6-8aeb-416a-a825-77e930ce4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch_input, *, tokenizer, word_freq: torch.Tensor):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    word_freq_logits = []\n",
    "    \n",
    "    for item in batch_input:\n",
    "        seq = item[\"seq\"]\n",
    "        ids = torch.tensor(tokenizer.tokenize(seq))\n",
    "        mask = torch.ones_like(ids)\n",
    "        logits = process_fn_in_collate(\n",
    "            word_freq.gather(0, ids)\n",
    "        )\n",
    "        \n",
    "        input_ids.append(ids)\n",
    "        attention_mask.append(mask)\n",
    "        word_freq_logits.append(logits)\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True)\n",
    "    word_freq_logits = pad_sequence(word_freq_logits, batch_first=True)\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"word_freq_logits\": word_freq_logits\n",
    "    }\n",
    "\n",
    "collate_fn = partial(collate, tokenizer=tokenizer, word_freq=wf_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adec62cd-06a3-4a73-ab53-9ee7919a5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    sprot_train,\n",
    "    batch_size=args.batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb10d7d-dfae-468b-8fa4-d015b0ef4d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[23, 10,  0,  ..., 25, 25, 25],\n",
      "        [23, 10, 16,  ..., 25, 25, 25],\n",
      "        [23, 10,  8,  ..., 25, 25, 25],\n",
      "        ...,\n",
      "        [23, 10,  0,  ..., 25, 25, 25],\n",
      "        [23, 10,  3,  ..., 25, 25, 25],\n",
      "        [23, 10, 15,  ..., 25, 25, 25]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'word_freq_logits': tensor([[-0.9607, -0.0456,  0.0322,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9570, -0.0418,  0.0042,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9610, -0.0459,  0.0063,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.9601, -0.0449,  0.0329,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9164, -0.0013,  0.0587,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9635, -0.0484,  0.0073,  ...,  0.0000,  0.0000,  0.0000]])}\n",
      "torch.Size([64, 505])\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(train_loader))\n",
    "print(sample_batch)\n",
    "print(sample_batch[\"input_ids\"].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be8b942d-1faa-4bc3-ae1d-421414e5f5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProteinBERT(\n",
      "  (embed_local): Embedding(26, 128)\n",
      "  (embed_global): Sequential(\n",
      "    (0): Linear(in_features=8943, out_features=512, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x TransformerLikeBlock(\n",
      "      (wide_and_narrow_conv1d): ConvBlock(\n",
      "        (conv_narrow): Sequential(\n",
      "          (0): Rearrange('b l d -> b d l')\n",
      "          (1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=same)\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): Rearrange('b d l -> b l d')\n",
      "        )\n",
      "        (conv_wide): Sequential(\n",
      "          (0): Rearrange('b l d -> b d l')\n",
      "          (1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=same, dilation=(5,))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): Rearrange('b d l -> b l d')\n",
      "        )\n",
      "      )\n",
      "      (dense_and_broadcast): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Rearrange('b d -> b () d')\n",
      "      )\n",
      "      (local_ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (local_dense): Sequential(\n",
      "        (0): Residual(\n",
      "          (fn): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (global_dense1): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "      (global_attention): GlobalAttention(\n",
      "        (to_q): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=256, bias=False)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "        (to_k): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=False)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "        (to_v): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=512, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "      )\n",
      "      (global_ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (global_dense2): Sequential(\n",
      "        (0): Residual(\n",
      "          (fn): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (local_head): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=26, bias=True)\n",
      "  )\n",
      "  (global_head): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=8943, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n",
      "\n",
      "embed_local\n",
      "embed_global\n",
      "embed_global.0\n",
      "embed_global.1\n",
      "blocks\n",
      "blocks.0\n",
      "blocks.0.wide_and_narrow_conv1d\n",
      "blocks.0.wide_and_narrow_conv1d.conv_narrow\n",
      "blocks.0.wide_and_narrow_conv1d.conv_narrow.0\n",
      "blocks.0.wide_and_narrow_conv1d.conv_narrow.1\n",
      "blocks.0.wide_and_narrow_conv1d.conv_narrow.2\n",
      "blocks.0.wide_and_narrow_conv1d.conv_narrow.3\n",
      "blocks.0.wide_and_narrow_conv1d.conv_wide\n",
      "blocks.0.wide_and_narrow_conv1d.conv_wide.0\n",
      "blocks.0.wide_and_narrow_conv1d.conv_wide.1\n",
      "blocks.0.wide_and_narrow_conv1d.conv_wide.2\n",
      "blocks.0.wide_and_narrow_conv1d.conv_wide.3\n",
      "blocks.0.dense_and_broadcast\n",
      "blocks.0.dense_and_broadcast.0\n",
      "blocks.0.dense_and_broadcast.1\n",
      "blocks.0.dense_and_broadcast.2\n",
      "blocks.0.local_ln1\n",
      "blocks.0.local_dense\n",
      "blocks.0.local_dense.0\n",
      "blocks.0.local_dense.0.fn\n",
      "blocks.0.local_dense.0.fn.0\n",
      "blocks.0.local_dense.0.fn.1\n",
      "blocks.0.local_dense.1\n",
      "blocks.0.global_dense1\n",
      "blocks.0.global_dense1.0\n",
      "blocks.0.global_dense1.1\n",
      "blocks.0.global_attention\n",
      "blocks.0.global_attention.to_q\n",
      "blocks.0.global_attention.to_q.0\n",
      "blocks.0.global_attention.to_q.1\n",
      "blocks.0.global_attention.to_k\n",
      "blocks.0.global_attention.to_k.0\n",
      "blocks.0.global_attention.to_k.1\n",
      "blocks.0.global_attention.to_v\n",
      "blocks.0.global_attention.to_v.0\n",
      "blocks.0.global_attention.to_v.1\n",
      "blocks.0.global_ln1\n",
      "blocks.0.global_dense2\n",
      "blocks.0.global_dense2.0\n",
      "blocks.0.global_dense2.0.fn\n",
      "blocks.0.global_dense2.0.fn.0\n",
      "blocks.0.global_dense2.0.fn.1\n",
      "blocks.0.global_dense2.1\n",
      "blocks.1\n",
      "blocks.1.wide_and_narrow_conv1d\n",
      "blocks.1.wide_and_narrow_conv1d.conv_narrow\n",
      "blocks.1.wide_and_narrow_conv1d.conv_narrow.0\n",
      "blocks.1.wide_and_narrow_conv1d.conv_narrow.1\n",
      "blocks.1.wide_and_narrow_conv1d.conv_narrow.2\n",
      "blocks.1.wide_and_narrow_conv1d.conv_narrow.3\n",
      "blocks.1.wide_and_narrow_conv1d.conv_wide\n",
      "blocks.1.wide_and_narrow_conv1d.conv_wide.0\n",
      "blocks.1.wide_and_narrow_conv1d.conv_wide.1\n",
      "blocks.1.wide_and_narrow_conv1d.conv_wide.2\n",
      "blocks.1.wide_and_narrow_conv1d.conv_wide.3\n",
      "blocks.1.dense_and_broadcast\n",
      "blocks.1.dense_and_broadcast.0\n",
      "blocks.1.dense_and_broadcast.1\n",
      "blocks.1.dense_and_broadcast.2\n",
      "blocks.1.local_ln1\n",
      "blocks.1.local_dense\n",
      "blocks.1.local_dense.0\n",
      "blocks.1.local_dense.0.fn\n",
      "blocks.1.local_dense.0.fn.0\n",
      "blocks.1.local_dense.0.fn.1\n",
      "blocks.1.local_dense.1\n",
      "blocks.1.global_dense1\n",
      "blocks.1.global_dense1.0\n",
      "blocks.1.global_dense1.1\n",
      "blocks.1.global_attention\n",
      "blocks.1.global_attention.to_q\n",
      "blocks.1.global_attention.to_q.0\n",
      "blocks.1.global_attention.to_q.1\n",
      "blocks.1.global_attention.to_k\n",
      "blocks.1.global_attention.to_k.0\n",
      "blocks.1.global_attention.to_k.1\n",
      "blocks.1.global_attention.to_v\n",
      "blocks.1.global_attention.to_v.0\n",
      "blocks.1.global_attention.to_v.1\n",
      "blocks.1.global_ln1\n",
      "blocks.1.global_dense2\n",
      "blocks.1.global_dense2.0\n",
      "blocks.1.global_dense2.0.fn\n",
      "blocks.1.global_dense2.0.fn.0\n",
      "blocks.1.global_dense2.0.fn.1\n",
      "blocks.1.global_dense2.1\n",
      "blocks.2\n",
      "blocks.2.wide_and_narrow_conv1d\n",
      "blocks.2.wide_and_narrow_conv1d.conv_narrow\n",
      "blocks.2.wide_and_narrow_conv1d.conv_narrow.0\n",
      "blocks.2.wide_and_narrow_conv1d.conv_narrow.1\n",
      "blocks.2.wide_and_narrow_conv1d.conv_narrow.2\n",
      "blocks.2.wide_and_narrow_conv1d.conv_narrow.3\n",
      "blocks.2.wide_and_narrow_conv1d.conv_wide\n",
      "blocks.2.wide_and_narrow_conv1d.conv_wide.0\n",
      "blocks.2.wide_and_narrow_conv1d.conv_wide.1\n",
      "blocks.2.wide_and_narrow_conv1d.conv_wide.2\n",
      "blocks.2.wide_and_narrow_conv1d.conv_wide.3\n",
      "blocks.2.dense_and_broadcast\n",
      "blocks.2.dense_and_broadcast.0\n",
      "blocks.2.dense_and_broadcast.1\n",
      "blocks.2.dense_and_broadcast.2\n",
      "blocks.2.local_ln1\n",
      "blocks.2.local_dense\n",
      "blocks.2.local_dense.0\n",
      "blocks.2.local_dense.0.fn\n",
      "blocks.2.local_dense.0.fn.0\n",
      "blocks.2.local_dense.0.fn.1\n",
      "blocks.2.local_dense.1\n",
      "blocks.2.global_dense1\n",
      "blocks.2.global_dense1.0\n",
      "blocks.2.global_dense1.1\n",
      "blocks.2.global_attention\n",
      "blocks.2.global_attention.to_q\n",
      "blocks.2.global_attention.to_q.0\n",
      "blocks.2.global_attention.to_q.1\n",
      "blocks.2.global_attention.to_k\n",
      "blocks.2.global_attention.to_k.0\n",
      "blocks.2.global_attention.to_k.1\n",
      "blocks.2.global_attention.to_v\n",
      "blocks.2.global_attention.to_v.0\n",
      "blocks.2.global_attention.to_v.1\n",
      "blocks.2.global_ln1\n",
      "blocks.2.global_dense2\n",
      "blocks.2.global_dense2.0\n",
      "blocks.2.global_dense2.0.fn\n",
      "blocks.2.global_dense2.0.fn.0\n",
      "blocks.2.global_dense2.0.fn.1\n",
      "blocks.2.global_dense2.1\n",
      "blocks.3\n",
      "blocks.3.wide_and_narrow_conv1d\n",
      "blocks.3.wide_and_narrow_conv1d.conv_narrow\n",
      "blocks.3.wide_and_narrow_conv1d.conv_narrow.0\n",
      "blocks.3.wide_and_narrow_conv1d.conv_narrow.1\n",
      "blocks.3.wide_and_narrow_conv1d.conv_narrow.2\n",
      "blocks.3.wide_and_narrow_conv1d.conv_narrow.3\n",
      "blocks.3.wide_and_narrow_conv1d.conv_wide\n",
      "blocks.3.wide_and_narrow_conv1d.conv_wide.0\n",
      "blocks.3.wide_and_narrow_conv1d.conv_wide.1\n",
      "blocks.3.wide_and_narrow_conv1d.conv_wide.2\n",
      "blocks.3.wide_and_narrow_conv1d.conv_wide.3\n",
      "blocks.3.dense_and_broadcast\n",
      "blocks.3.dense_and_broadcast.0\n",
      "blocks.3.dense_and_broadcast.1\n",
      "blocks.3.dense_and_broadcast.2\n",
      "blocks.3.local_ln1\n",
      "blocks.3.local_dense\n",
      "blocks.3.local_dense.0\n",
      "blocks.3.local_dense.0.fn\n",
      "blocks.3.local_dense.0.fn.0\n",
      "blocks.3.local_dense.0.fn.1\n",
      "blocks.3.local_dense.1\n",
      "blocks.3.global_dense1\n",
      "blocks.3.global_dense1.0\n",
      "blocks.3.global_dense1.1\n",
      "blocks.3.global_attention\n",
      "blocks.3.global_attention.to_q\n",
      "blocks.3.global_attention.to_q.0\n",
      "blocks.3.global_attention.to_q.1\n",
      "blocks.3.global_attention.to_k\n",
      "blocks.3.global_attention.to_k.0\n",
      "blocks.3.global_attention.to_k.1\n",
      "blocks.3.global_attention.to_v\n",
      "blocks.3.global_attention.to_v.0\n",
      "blocks.3.global_attention.to_v.1\n",
      "blocks.3.global_ln1\n",
      "blocks.3.global_dense2\n",
      "blocks.3.global_dense2.0\n",
      "blocks.3.global_dense2.0.fn\n",
      "blocks.3.global_dense2.0.fn.0\n",
      "blocks.3.global_dense2.0.fn.1\n",
      "blocks.3.global_dense2.1\n",
      "blocks.4\n",
      "blocks.4.wide_and_narrow_conv1d\n",
      "blocks.4.wide_and_narrow_conv1d.conv_narrow\n",
      "blocks.4.wide_and_narrow_conv1d.conv_narrow.0\n",
      "blocks.4.wide_and_narrow_conv1d.conv_narrow.1\n",
      "blocks.4.wide_and_narrow_conv1d.conv_narrow.2\n",
      "blocks.4.wide_and_narrow_conv1d.conv_narrow.3\n",
      "blocks.4.wide_and_narrow_conv1d.conv_wide\n",
      "blocks.4.wide_and_narrow_conv1d.conv_wide.0\n",
      "blocks.4.wide_and_narrow_conv1d.conv_wide.1\n",
      "blocks.4.wide_and_narrow_conv1d.conv_wide.2\n",
      "blocks.4.wide_and_narrow_conv1d.conv_wide.3\n",
      "blocks.4.dense_and_broadcast\n",
      "blocks.4.dense_and_broadcast.0\n",
      "blocks.4.dense_and_broadcast.1\n",
      "blocks.4.dense_and_broadcast.2\n",
      "blocks.4.local_ln1\n",
      "blocks.4.local_dense\n",
      "blocks.4.local_dense.0\n",
      "blocks.4.local_dense.0.fn\n",
      "blocks.4.local_dense.0.fn.0\n",
      "blocks.4.local_dense.0.fn.1\n",
      "blocks.4.local_dense.1\n",
      "blocks.4.global_dense1\n",
      "blocks.4.global_dense1.0\n",
      "blocks.4.global_dense1.1\n",
      "blocks.4.global_attention\n",
      "blocks.4.global_attention.to_q\n",
      "blocks.4.global_attention.to_q.0\n",
      "blocks.4.global_attention.to_q.1\n",
      "blocks.4.global_attention.to_k\n",
      "blocks.4.global_attention.to_k.0\n",
      "blocks.4.global_attention.to_k.1\n",
      "blocks.4.global_attention.to_v\n",
      "blocks.4.global_attention.to_v.0\n",
      "blocks.4.global_attention.to_v.1\n",
      "blocks.4.global_ln1\n",
      "blocks.4.global_dense2\n",
      "blocks.4.global_dense2.0\n",
      "blocks.4.global_dense2.0.fn\n",
      "blocks.4.global_dense2.0.fn.0\n",
      "blocks.4.global_dense2.0.fn.1\n",
      "blocks.4.global_dense2.1\n",
      "blocks.5\n",
      "blocks.5.wide_and_narrow_conv1d\n",
      "blocks.5.wide_and_narrow_conv1d.conv_narrow\n",
      "blocks.5.wide_and_narrow_conv1d.conv_narrow.0\n",
      "blocks.5.wide_and_narrow_conv1d.conv_narrow.1\n",
      "blocks.5.wide_and_narrow_conv1d.conv_narrow.2\n",
      "blocks.5.wide_and_narrow_conv1d.conv_narrow.3\n",
      "blocks.5.wide_and_narrow_conv1d.conv_wide\n",
      "blocks.5.wide_and_narrow_conv1d.conv_wide.0\n",
      "blocks.5.wide_and_narrow_conv1d.conv_wide.1\n",
      "blocks.5.wide_and_narrow_conv1d.conv_wide.2\n",
      "blocks.5.wide_and_narrow_conv1d.conv_wide.3\n",
      "blocks.5.dense_and_broadcast\n",
      "blocks.5.dense_and_broadcast.0\n",
      "blocks.5.dense_and_broadcast.1\n",
      "blocks.5.dense_and_broadcast.2\n",
      "blocks.5.local_ln1\n",
      "blocks.5.local_dense\n",
      "blocks.5.local_dense.0\n",
      "blocks.5.local_dense.0.fn\n",
      "blocks.5.local_dense.0.fn.0\n",
      "blocks.5.local_dense.0.fn.1\n",
      "blocks.5.local_dense.1\n",
      "blocks.5.global_dense1\n",
      "blocks.5.global_dense1.0\n",
      "blocks.5.global_dense1.1\n",
      "blocks.5.global_attention\n",
      "blocks.5.global_attention.to_q\n",
      "blocks.5.global_attention.to_q.0\n",
      "blocks.5.global_attention.to_q.1\n",
      "blocks.5.global_attention.to_k\n",
      "blocks.5.global_attention.to_k.0\n",
      "blocks.5.global_attention.to_k.1\n",
      "blocks.5.global_attention.to_v\n",
      "blocks.5.global_attention.to_v.0\n",
      "blocks.5.global_attention.to_v.1\n",
      "blocks.5.global_ln1\n",
      "blocks.5.global_dense2\n",
      "blocks.5.global_dense2.0\n",
      "blocks.5.global_dense2.0.fn\n",
      "blocks.5.global_dense2.0.fn.0\n",
      "blocks.5.global_dense2.0.fn.1\n",
      "blocks.5.global_dense2.1\n",
      "local_head\n",
      "local_head.0\n",
      "global_head\n",
      "global_head.0\n",
      "global_head.1\n"
     ]
    }
   ],
   "source": [
    "def denoise(targets, timestep, attention_mask, *, model):\n",
    "    ret = model(targets)\n",
    "    #ret = model(targets, attention_mask=attention_mask)\n",
    "    # print(\"denoise output:\", ret.shape)\n",
    "    return ret\n",
    "\n",
    "with open(\"../weights/epoch_92400_sample_23500000.pkl\", \"rb\") as f:\n",
    "    _, pretrained_model_weights, _ = pickle.load(f)\n",
    "\n",
    "model = ProteinBERT(tokenizer.vocab_size, consts.GO_ANN_SIZE)\n",
    "print(model)\n",
    "\n",
    "trainable_params = load_pretrained_weights(model, pretrained_model_weights)\n",
    "model = model.to(args.device)\n",
    "denoise_fn = partial(denoise, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f059ff8-7325-472b-849e-7e61f881f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/.miniforge3/envs/proteinbert_gen/lib/python3.11/site-packages/torch/_compile.py:24: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  return torch._dynamo.disable(fn, recursive)(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = args.optimizer_cls(trainable_params, lr=args.lr)\n",
    "if args.warmup_scheduler:\n",
    "    warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "        optimizer,\n",
    "        lr_lambda=lambda n: n / 10000. + 1e-3 if n < 10000 else 100. / math.sqrt(n)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5497e45a-ddc8-4618-8139-3a7b25304847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using standard schedule with num_steps: 4096.\n"
     ]
    }
   ],
   "source": [
    "sample_cls = Categorical()\n",
    "\n",
    "diffusion_schedule = mask_diffusion.create_discrete_diffusion_schedule(num_steps=args.num_steps)\n",
    "diffusion_instance = mask_diffusion.MaskDiffusion(\n",
    "    dim=tokenizer.vocab_size,\n",
    "    schedule=diffusion_schedule,\n",
    "    tokenizer=tokenizer,\n",
    "    sample_cls=sample_cls,\n",
    "    word_freq_lambda=args.word_freq_lambda,\n",
    "    device=args.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3410a448-cb86-44f9-be96-17fd4847930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5082/5082 [06:03<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^MWGLTPTLDMSFAGAQKGLIDHYILRFALIEELVSVVAQNEGADLATPPNGELGVYDSGFEDINLKSLVAYGVVSIPARTRPDGEALLVDHYAVASAAGADDILAGGRDGVLPGLLLVKMEFVVIDYSESLYRYDLD$$IELRVIGTPQLDTPDKEVSDGSASKHKRQFLWYVACPTILNGTIMRMRTGHIAEREEGAV\n",
      "^MFFSAGTFLYGMAVSISISMAKRVTLDGGRVAESAVLNSYAWYKDIVAQCSPYENEFFFDNFSEVVTVAMVLLTDYLGPKRLSQIIKEAYFIARISCSNRSHELHPHLSIDPRGLLLAIGGYLGLEHT$LNKGVCEFLLIPGSANGPLSRPSAILSKLAVKDAEIRTSTPTAALKGLPQNGAKRMNANRMGLAASQTGL\n",
      "^MRYMGAFDQWERHPYRLACSEPQLEASDSTCHLRLINGLEEIST$SRSILHFADVHITINGVTFYKDLVSIALLPLSKKLFLAAPFFISRQGFFLQYTAARLFTQYEGSSQVMKILPEQHICR$TFDNRLLWQLLVLEAGSSHIIKVTPSFVPLPGFEVLDDSGGCGGNQKIGQATEEEVVALFPNGVRAIMVVSLGPG\n",
      "^MRKEWRISLAARFPAHFIRSVEAMSPPLSFMYVVDVGTKSGASSAIVVLNLYRTDFITTAYAYFTRGFINLAPLIFIHKMFSQPLTVMQIRRRKIVHRPVVGDFSNHALGAINKVNGQPTGYATNLLQATRSRVDTGDCNVIDAVLTEALGSGEWKSAFPERIGIIPMTIVARRTDLALLAFDFRSGEIAIELLDADDG\n",
      "^MMQEGDLPIPGYAAFMVYGDPTQEEIIIAKKRFNQYAGLSQFNIKTRAIEKNSALVPVDIMYFTKHMKDPSMHKVENRELHAGEGELPAQTSLTIQVAVPNLWPTMHRFEPWGEYLMTGEQKEILSGAQYKGTMFPFLMLSTGLEAPKCSKRGRLSANKDREINTSRIPPMLTPPEWPIVISAEQAEHTDNTGSNFLIT\n",
      "^MLHSPPTKRVKVDMARTAFHRKSATLADAASLAGFGNYVVSPSNLSLVAPLGTKWGVEERSANEDTMIDPLARSDYRNITPYPFDLTLEMEKESGSIDAEGSHPVAYPGDVMIEVAVMIQAAIGPGRKIGKEIMPGLLLETRIQELTVLENMLPKTLQTRPTVKFTVVGFRLKLSNYAFYQEILVVTGQGGITVVLGGG\n",
      "^MADLSTRSLQIVFPKFGIGTVKSYLYFSSYADPATPTQPQPPTCMRAGYYSAAHMMNSPKERYLVGASALLTIPYRSGDTELVLVVPRFGVVIVCQVLAPGGPANDSQETIDGEVILRVVEYAEDVTVSKYDSSLATGDFSGPCLHTAVIANRYVENRGAVAFGTSTAYDLWRLSFINRARIVRLREVHPTSEFRTSGG\n",
      "^KGKHPLVYLDFPHTDFGFMGIVFTKQDVAALEVAVHAEVLALGEGFVHNYPLTVGTAIEIVRQGLFNTER$RDYVAHFLASVLLKGGWGASVLLDPKPSASRRGGGGNAIFAELAKQVYQIGRGAPRNMDQCCMLGKQKSSK$FRVQILVRVGAGKILGRFYRLKKSGPGTRIVALDTYPPPIFISETTKVYLDIKILG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5082/5082 [06:02<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^MSRIHPDISGIDAIEAKLAYAVVADLKRLIGKLRRQSLWRHPRPRRRMAAWAAQLEKPRGRRASADAIRIDTISAEPKLWEPREIMIGADITATITAAVGPAIDSGDIAAAARLIIIPRVPELRRRAAAIAAIAIQIIGPLPRYPSSPARTISRALRRTTVAALQRIAAIPAQPAFLHDIAGHDIPHPRRIITISPRHS\n",
      "^MISHQALRALASIRHVALRATRAVAVAIARAVEPEQRIARQYVRLAQRQLLAPIGAARAQEEFALTRAIRQKQAQIIREIKRIIADGPPPIAAPGIVIALPKEITIKRISSPEAMRGRARRSELSQHADRPAWVQAADITSVDQAIADMPEALRCLITIDAEDVPTIDDSRAALGIPALRPVVGWVSRQSVQIIRRIRK\n",
      "^MQVIAALRAIVRWNSAPDSTLSDRIDHYHLIDPELTDILALAIEQLPPHAAVAAIAATLRRIRASGSKRRPRIRLLRKADWLRLPKEQDQHLPAPDCITILGAITEPARIRVVIASSLLRLADAQHRIVLGSAAAGASASERLYHELRPLLRRAIDQAITPLAATLAAISDTVRQAGRAAAIRPRRQTIMIDRPARRIK\n",
      "^MPPTDAIVVDELSYESAAPLAAIVVVGMPIRHTAIPDPSTVMADCDHVDAVEWIAAPWRRADLIARIIPPAIHAAAASQRQGQRIGTIPRPGQPPRQMVAWPPRPDADIAVAAATVDAIAAEITAAIAAIPQGAAIRALLRKAAEPRKRAAVRRARQMIARLGRLAIPQDGIIIDAARPITRYPRPTVIAITAPPRERS\n",
      "^MRFEIDLAAAAIAVAVHPRLVHDAIISHPDRDISLPWREASPPSPRRTRRIRTIRARIAQAIEPAQPPMPALGTIPRDPTIDIPIIAAAPSIAAAIAAIAAAPPQAISAIAAAAFRRLPARIPSPRGRQHQEIIPTEIDPVIHSIVQASPAPEIIHPIPLLAPSYATTSDGAIPLALPDQRTIRIIASAEARIISRIRR\n",
      "^MNVPIAPRARATGIAIDLAVHAPIPLTPPQHGRHDAIVAVPADEALDAGAADVRERRQLTMPPRAPGQRWAWTLRTLPAKQQCPALPPEKVDMIALQATDAQPILITTPAIAAAPRVIAAVIPRPPARAIPQAIIAAPHRPLLRLPAPPRIPLPRRIRWALAPDRAGIVEIAARDIEAFQRVVAIDRIPASEAIAMSRR\n",
      "^MMSTDARDVLLTPHGPSIPQDPRDITRTIAINTIASPQDPVIAAPATAAAAAIRTIRAQRIGEIAIVRIARRQDDLDRITAIIKQQPLAIVHAAGRHRFPPREILAKEGIRAKILRKKKKWQKLKPPQRPHMLKPYAALPITIAAHADSADIAIAAAVEVPAGDAIIVAAVAAWISADPRGIFVRKVVEIFRQLKAEKK\n",
      "^VDEDSLVTARRRRRQEAIMLAQSSKRQKFIICATGRRIRALDIDVTNTYKLEADMVLDAADTIRAGIYDTLEEIRKAPRQIRRRMTIARRLRRKAAIISSAKKQIVRAISISEKIRRATAMLRARKSWRKQPEEIILAQHQEAMHSEQAPATAVPADIIELFIPEVVARDYAIVVPDITSAQPDVISLRERIATSWRRR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5082/5082 [06:03<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITRHNVKIVVGKPNVVLSQGHEIISFVNVQKKSIPKCPFRIHILYCTIDIIDDRPIKVTAKIFQKINDSFSDCPNETVIIYVIETDNEKQGVVIKVVTDPDPHVFVYTKNKETDFSTPMIKMGETGECTIIINQDPGTITIVEECTKKTIAKGATRFILTKEIKDVIKPPKTIFCVDDVGIVAKTEGIVERFPVHIKD$\n",
      "IIKNIFNVASFEEIDLENDEVITKKFTGILIDFEHVSEKEAQVPFKTATNPATIIEFNIFIIAGTKGIVKETIKMKKVKIANQITKVYIDKTIKNVFKVLKIIDKQAKITKIHILKKKKQVHEKVIVRGAADAVTEIFKINPDKVVGVIATGFDVVADQKEREHNIIANGNVITKAAAILMTMVILQDTIREIQKSFKI$\n",
      "^MKLVKTNEKERKIIETTDGDIIREEIFEKTIKDKDARVMVAEKTITVTDLSVHMGIDIAEMRKKLNVASTGGILTIRETEPIVPVGDGTIDRIDTPDHDVIITKDQIKEETEVEITKVRRFLGKETATTLDKGEEVEAVDYDIMIKPVGTTAPEPGTGDSIKTETKGILIAKGGKIDVKGAVVRAVVVTENKIHHKGE$\n",
      "^MGEVTIHKSGRGDIDFARGPTIVKPFVIITIGKRIPPDVPKAKKTTDTFEADDNTPVVVDNTKSTVDDEVTMKPGVGAMDYKTEDRIIVTTGKIKGVDFEEIPTVIGIPKIMHRPKILVDDITADRLEIKAILDIFKKDPISDVSVAVGKARIKKVTGIGIAITDMISIDGDGIHFYKDTKSLATEKRIPTTAHIKSAK\n",
      "VIEFIRKKYQTKDIPITIAEYFVAFFGVTIVRENNETSIECIINKNITHIIRIVAVADIKKKEIKVIDKPFICIICDVTDKAQPVAAPTTVEDEHHNVVAIPEAGTDTITDKDILPIPIKPTAEAIGIKKIEGGHTHIRTFKDIEFINKKDVKHIVFYKKEEKVIVKRGITVIFSSDDFFIIPIDVKHHTETTKHKHKAK\n",
      "^MDNIDHGTKFKVELTMATNDAVIEILGPFTFIFSATRKYGPEVICTPENVIPDGAAVVKVKVEIPDYFRKIKNDRIIQIVVAAIGDAVIMKPDPVIIDDLKRMIVKLVGTHKDKATTEVAVEDGVKARGLTGEEADVIKAEFAVIEVCVITVKGNIHGKGGSGGEIAHLRVCVITHNKIPPGIVKRINHIIKDIETHAK\n",
      "^MSQIRTSCHICNHIINARPIQKVVKDFTEFCPYIIKAIDKTPFAYRYPVTKTNRKIKYVKPAPIIEYTPYIIFTTFIVTYKEPVKPSIIIIDCAKKTDGTQINEHGDTDIKATVKIVPFILKKKTDPYELKKESINDNIKDKAVVTKHIIIMLTMEVVDYIFRKKPETIDHKCPVIPADIKTAIRITTITKKIIKGFEK\n",
      "^MKSGKEKTPTGHIITKVKTGEAEGIERGGTKIITVDDEVIEQYILGRKALMQGKAINVPGVVRNGAIAIVSIDDINWHKHFFSAGAITAGEGAVEYPGDKVLVNDMIVTIKKDTVTIIEPDGYGPEGIIVGTEVHKIDHGSNAADGVKGRITPVTKIQSDTFPMPYMKYANRVVIVTVMDIMMMTMLKKFKVLKKHRKS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5082/5082 [06:04<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^MSSIPAPWFAAAAPPRLFQAQAAAVIAQIAGAGFEPLLQEFAEIPTIEPVEGEEPAIFAARGAQAIAPGSIQVIDAIEVLEGQYDGEESILAAFIQPNLQEYVEQSAFARQIATGEREREAAVPTPVVAILAEAGLQESIAILPEEQVGEPIPAGVPAGLPTAAASPAPVAVAAIARLLFAGIAFLLLEAQFHYPEEAS\n",
      "^MAAFGAESPSRAAIAIALTRIAEACPLVEFEWVAPERDELEIFSSAPVPAAAAVAGAEAQTALAAAPEAEPILGIAEEMPPELAAALEAELGESLAGAARAIVGIGGRPITAPGLPEAPQAIMRRFARPLAAIAAELVGNEAFASVEALVGVEIQEFTPIIEAAGPERREEAIVPAIAEAFPEIQPYAEVIAAFFPEFS\n",
      "^MGAVLFELASALAQPPIEFNRNQAIIPAQAAMELSPLAAPAPPRIAASRKLAVARFGAENEQFIAISAICPELPQWFTTFQALIERNSLNQIFASAQSWLRGTGAQPFLEVGIGIDGLSRSQASIWPIEGAIRRFLVAIGQGEGEAAIVWAASFPEMRESIEALVPSSQAPPNVELGQPFIAAFPILREAQIPFEAEIA\n",
      "^MSASIWEQLGIPAFRALQAGGIGIIEAPEEVRGLRFATAIPALSGQATIAAQAAIGRIPQIIAANGFIEFESARLYAAEGEAVPFDGVLGFRFAEELAAALAATRVPGAATVRAIEPVVPAEEFALAAGQGRILVAAGAAQILSIFARAPQREALRGFGRGASLTIPREGFAGSLAALPEFAIAIEGEQEAPWIIAIAE\n",
      "^MNPSFLAAFGIIPAIFAPARFSAAVAAGIALAAGLPPGFAIALALEGRLQLAEAAEPAPIVTIANEPQLSPVQAEIAASARLQIFLNNSPFQPAQIQAIAALPQIARPANIFTSQEGEPIAIAASQRALVAAGQQGSIFASIQREIAERIPAAIQEAIEAGIPGNQLAVIAAFAQPEQIEAANPIIFIQLLRAFPEFIA\n",
      "^MRLFPAFVPALPAPAALALAPAAAAAAAARALRLLDLGRAASLIPWRFAMIAEDAALVRGEPAFIAGLPERAPIPASAGARARVALPERFILLAQRRIAIIARAAAPQAAFTAVLARIFARAPIARAILPALWYARREQPPIFPARFRILPFWPLGARAAPARAFAARAIAEIALAGWLARLPFEAALAWLQEFAEIAQ\n",
      "^MSNPFNFFLGPPAAIIDAFQEISAIANAAGQAAAAARVIPATAAQGFFIPILQAAEPQAIPQTLSFNNEERFRPPIQTAAPEPAAIIAGIELAEAAQIIISRIPAPIIEFAGLAIPEPEEPSTISEAQAESNVEIGSEEATTLEEVIAQLQIALPAFIMAAGQQFNEAIAIAGQLGNGGAIIRPIAAGEIHECIEEFAS\n",
      "^MSAFPAISFIQGLRIAAEAVRGAAAGEIVAFPSEVPEEWALAVSALIEQGEIPRISATPARFIAAMAFPRFIAIEAPELRGAATRRIIAEVLAFGPEIAELLPLEAAAGQAGIVPAESLFPVREALRAPEPEAIAARAARALAAVAARGISFAGSAIAIMPEAWFAESREPRFELAAIALEAAEQGLQAFLEIIAPAEQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5082/5082 [06:12<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^MKITTIHNLIAEKKKATERYYPTAVEHYFLRVRMALLIMFELLTPHGKESKHFPEVKLAQVILLKCGFAACNMEHRVKLAEHVLYTQKKKTGHRVPTPDALCDVEIMTMKTGIEAVEIAKKRLVAMQWLETDMHRTTFHSGHYRSGRAEIMTARALLDISGLKYVGEGTDLVQPKAQVAGMKHGITLCSPGIETSPEAK\n",
      "^MVELRQKRPCSTIQLNFVNPWHLVTIQIVVVGMGSGEHVFKSIFEHCYTQVPGEGRMVLTDSLKLGHVKIDMVVQMTLERSGTTLCGLRLENALTFYGIWRYVNHAQEDLKQGYKVHGQWLVRLIPAWKLFQSTNKDHHNVVVYVIGQMRIPEKAWLSVHAILKCCADLKKCHHFFGKRKGVPVTIVVSCFFITQWPR$\n",
      "^MSIFTKEVCSICGSILRMTKLRIVMQGMKKTLVLHLLMPTEIFEKPQTTLIMEQIRFMPCVLPAGGHAYIMRNVETVRISLVGHVICELPFSLKQMCERFQYSGRLIGITFVTQVEFYTMCSSGTMLTVQRLPIISQPLLQPFKKRPHLQGQGWLPKTITTVMLRSSELMLKGYMPVVIVILLIAILLMHKRHHKHLKK\n",
      "^MSLDNPCPSCTPPPTDIYQICTWVVSHSSGVDMVHVVVLLMGAEGLFRFEDITRLIQSASTFRVVSISECVWRSGILARSEGYNVGLYQQLKQMQKLGVEELREILKEMNGVVGTTSMHVKVFEFMNNGHTYVYKRSHACSVTGDPRGAGSLYENHSPVTRDMMQGTFRRGYTKGQPFAGGVPGIVHLVGCWIYGPAEK\n",
      "^MKHRSEPTLAKSQQKSLVTGLQMPVRVGWDLAEIMQFIMNQFTCFECIFDKLFEHVNITWKELCKSAHVIEVLNRFQVIDRLKCAELKTFCVPEITDEFCVAHLALTKRIEKRLQKPYLAESIGMICLLVIVVISVCSAGFVVTCVKRLQWFQKFNDHGLCTLLALRVLDGPFPMEPFCIYITSLPHLLFVQHCRHFRK\n",
      "^MSMKLIQIPQRARTQTLPALNGTALVRLGQVIQIKLALERLSSYSNPEQLEQISTLGMLLIWNMLAFMGYFFPEIQIMSQWQFNKPLNLMTWLRMQPWWKQTGLGVIMTDIQMGLFLIILLILLCMLVTLMEVWQLWIMDPQTLPQVTQTFRFVRGALAGQGINILCTKTSRKLLPEIAQSQRQKLGWQAWVMQLGHSK\n",
      "^MILTLILLVIAMQFTRTRWTPNLKHPLSIWGTPELPEHLIVGSVIPQPWIALSQYPIPRTTSWQLLGWRSTSGLLILIFDRGMLFTKAEVYQTRMVEMLKRVLLLQGYKRTITMCLDQLVQLPEIGMQRFQGFRNSGKLSAGFSPSTIMSLQAQTLEILFLEITTRCQLISKLAGRHLPILNEVLMQLRPKLFCKKTKS\n",
      "^MKVICKIRTTHTDERMMSKGKIPTMEFHLKLFCTFYMTHGRHFAVLLETTDGKMRMGLDAETTLMEKTDKKGPEVLVLRGEASKDLSEPNMETTLRWKPFASLDYVGVLVDKWKQAEDSEITKEFEGVGSELALLQAAQGVCTPFFALVRLLLENVKLDFDTISKPEIKPSIYDIDLMDLFDMYRANHTERILFVLEQ$\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5082/5082 [06:03<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^MSSPYTVYGITRCGEIAFKLTNLCISHEFTCSIPKVPYSNPKCIAYMMEILSMFYVGVRYGDETEYALISVTGEIAGLSQPVRDSGIRLRWEAKFPAKRVPLLKYVITRPLKYGPTLKNISRPSVGFQESIGAMGTKITFESAGQYGERIVFAQSDVAVLPQSIGAITTAVAQNPSYLRARMAVKKVLLKVRPNMPFKK\n",
      "^MRRWYVPYLLHSATMAMKLSCRARARDRLSRRTAGRRQRAFPSRGLSRLLMPDLVHPGIRLGRFACMFQVSYTERAYDRFRTLDFLLLALSRVSSRLDMFALRADQAMSPDPYLPAMVLVLARRHDPPIVTHCPRFVTERIIHRVLDATWRSGISTSMSCAYRRGLPRLAIYGVPVSAVMGPQQTLHPDWPARLPHPTS\n",
      "^MISPLADPLLTKQARRGWRSPILEPLYKTQMMSRHTIRNRAVKINDAALDLMRMFVAVSTVSRMITRRFHTPWTPDHKTPRYEGSHLVRTCCAIAPPYIGSFEISQLLEMGARDSGFFTRSYRKWSNDTPDMDIPAEQVLDLVRAHSFTPRTYITLTLKNRMDDTITVIYRDRCEGIHTLELLEMFAYTRYEPQPKPS$\n",
      "^MQIEKLIELLRNSRPLKRLCNDRKVNTPAHMYRPELYHGLSITGGMTYKTMMQVSKSHELGRANGVARLKITKMIDDEAVVAQIGQVYGNQDQYLGVASTIVQFSPLALMQGKEGVARYNSVEQEIRTFYVGAPLTVPSPDLEKAVRKYFSTKHARDEYTYQMSLYGYKTRPERVVGINFSVVTRIVKEIPWIVSQ$$$\n",
      "^MNFIRGIATWPSSSRLRAINLTLRDYYSMPILEVFTTRWKRSHFQLRMHSLITSLGIQSTSPTRMNLLRYDVKSPITMHLRLYGALRRRGAKAVVTRFRLRSFEQVPRGETEDMIEDGLPEVATSVDDLGRRQDRAFFMVYTMARRFLSPRLLLKRRTVGLAAKRFFEACSYPDFATIFYSDFIRDAEGIPTSHSTISK\n",
      "^MSLQVRMPIKFLMLALENPVKAHKELNAGERAVIELPIDVSLREIQGKFVSLSKNKFRKDPPTLWRASRHSDASKVQKQGNTMYGKLMTVILKLAKGGRPPYENGYMVLLETQNIKRIIENGKEVGTGSELDGNTIKRFFAIIGSNYSKINDFTYDIKMPIVKTEGKKILGNIEETGAETVWIRNLLKLGNNEEKNAF$\n",
      "^MKIAQNGQPAFRAKLFLREMVALLTYCPPLVYYYRPHKYGPLVRLRSSFEIYDMEGVLEYLGTTVLPFIHFDPAPEKSTYEKIAEVRTSLFIKDFDVFGACNAAVTNDEEKEYLMVYVHICERYTRAGTALTKGCKAEFVVRRDLMITLLKKHPLGISVAALRYFADKCNMITRLPPLTHREYQRLITAEFPAWAPLKK\n",
      "^MPYLLFIQYPGHVDYVLTTLYPVFGDDDGTVGAMFLLDRLPATGRIIKPCNRPDVLAGAESVMNEGENFKGYSRSGFQEVRWGGRMARAAQLKLESGGTLIEKGATIRTDYNPYKTHGVDIVATRQDGVTIAQMLIELIRREGRKTLRKMFLTVNKRNLFDPITNAEIYGFLDITGQNPYFSVVTDAGRPRGGSKL$$$\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5082/5082 [06:25<00:00, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^MVEVRPRTTGIMASDVFGTQGYLLDSLEDAFVETLIKKQCDSWGDEDYSDEAVAVVYWAGKEWERLFFYGDEITLCGVTTYLSSTYVSQTSNISTSKEWWAISKAFYDFTQKKLRTGEIAFDLNSKVWPTANAPRAYHYTPQDRVWSSCSSKTMTILAMVLTFSCHTILIEDFGDFYDYEYSDTSANYFGGSHEVELGK\n",
      "^MELPIDINGTGAHFLQRMLAGFDVAEAKNITRVLVHGAAIPLNGSLNNKMMKTDEIISDKLSQVSTKGYDALKIETSLSSLYEAYEYDKGSVRVTMEIYDLVLVTGVGMPDGVLVNIIASSKNGYSLQDEMSQLLTEVSSSPPKDIMMPEDSVLRMVYHFNSGSHHRVVLASESYLKDYVETGSSSEDMEAFVENNGKK\n",
      "^MSSMLRENISPGQRMWMVKCIHHSQSYTSKPKIISYIVSDILFSQAVWEDMVSSLGEFNELASVCSSISEKGFLWPEFSFKNHSAVLLHFDHRWSTSWYCLCHGVKLCSHHVSTYVWVYYDCVAVHTVTSIRTPGMVFVESSSNSDPGTTRPTISISKWSMRVCPLKEKDGYDFDCSVSEGIDVYGTEGSMIHTLEKSQ\n",
      "^NISSYGTYTIIRSMSISHRTSSIQGTYYTITTYNYTFVETTYRTMPSSIGQFVSGDPMIQLSTLSHQMLTESHTCNILLDLTDSWSSRSLSRETCKTGEWLENSETGYARGENRALVEPVTLEDEPTGWLNLLVWFSCFDATLAVVPILDCRSSGHTYVLKQGIYGVFTDGSTILSHSISEKESKECSGCMFIYT$GRK\n",
      "^MDVLCLTDLGWSRVGPSYDTRFSWTRLRVRTTFTELFGTGSEYGIGPSCFLYWAGGEHEGQDAYLATVIDVIHDLIILGTSSFYSRGDWFSEDASGYQACSVPLAEYGFVHELYYYKKSYWLGVSLHELRSAHLMRVDSAMQSIAKSMAAELNYNSVPVVLQGSRGVKAHEAYTVFVETYVWYSLKINTYVTSESSKEK\n",
      "^MSLRDWDFLETVVKWLSAQVLSDGLAHVRKREGYGFITLDSAWDLHLLVWMDPSVSRCTTPAYRAVECGTGISTSHSESIIHYVVWLTPGRIYLQWPFFWSWHHLHSCFTTRGYCKSWEYETISMVLAGANLVVLPPILVEKSYSWKRGEKPTYTVNLDNLSGALILSILCELALATMVMRLDFSVMANPIGLHTRPR$\n",
      "^MWLSVDLAAWMQKRWKVVYSVFSTYFTDIEKADAEYQAALHTQAHGAISTDKGQILSEQVAPLDGLEVLFHDFLGLPMTLVERSMTGVPWFIYDFLMVVLQSDGESHDGCCVSLDSHKAETLPWASDSPSEETGVQAQVLYLVWALDVHRGAHKLSGFESVAELPCLGATDFDGVAMADVSLADPTMDESFISAVRSE$\n",
      "^MANEKSPHVTWWKNSELREVSLLVILHLDCYKGSFFISGLSTDIDDGLRFCVYVVTVSSITHLLDSIDSKIDSEHLRPVTISSRECNGSCSENGKTGFDTTCKVGPKDFFERYAMFWVLENFGLNIDKLASAVIISGTSTWTSYYDEEGCEESDSHVRVSCSSWKDTVVLCSNGMKILFAESKLEVSASNFIEVSKEE$\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5082/5082 [06:07<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^MSEIRTHKLVCSVQQKLYEWKIELLVTKVGILCGLYLPGTGKSSTYIGNLQKTTLLELKGVCKECELKEGEDLLCAMIERALHQERILPLALQMDELGCELLNCLGSATSAAMLIKQKSMERPKKQKLEEACLPLRELLRQCQSYELCGELSGIPGELDLEHELKVFYQLVLIHPLMSAPINTIAAAKTSAAPLEKKLP\n",
      "^MHCSRAVLVGEAELCKMHSHVESNEPTCGLCGLVISSGIELPELKTLKHKAADILALRGGAYVGPCMAKVQCHVELQGCETPGHLKGSSTILSGIKLYEAPLLCEALTSICLELFEEVGVKVSLMTCPGVHRPEKLQQKLMQAVGMEKYNPLVGIACVSGAEALQLMPETRAAMKCLNLDEILASCGSLSAAAAEKAHE\n",
      "^MSQEQQHTLGVKTYLNSWESCVVYVVCHGCQQTKRRALLFSCGSSTSLWSSLLKQIGLSCTPVPQESAKMWMMKIALVSEELMEKLAKWEGKMAKACKVIALIELALRKKSRSNCVDKDGTYVCLNEMELCMALSSEKSRTCLIKARNLWEKYLLVLSQAPGVVVPLTSKASTHGYDLCSLGTTSPTSCSSCRAVMLDG\n",
      "^MCWAPEGVLCLLTALLKKQEMLCSKIVLNITLAIVLGRNSKKSCLETAALKPCQKKCAHCVEKACACQCQPCLYELTTVLLPRKASKKASWCQSITCNGLAAILPYGLSKKLLCQAQDLQKKPELWSVCKGCGEACIRAATPNERLKLVVVVSPQLVKLRQRSASPCPAALWLLCGKGYVILSESRLSAWLIHAAKPHN\n",
      "^MTAMLENPYLRATSSAAANAMLACETGLPCIALANVIVADMWAPLQAACPRLFSAGLTSDLPKHMDVVKVVCACSPPSVTVSPWLRALYAPTCLALLSAAMSWGETVRTSKDFQAMKYAYKPCSCRLALWHAIARASSTRKLPLPCYLTAYQPAVEDDLDACDVLPQKVAKAKALADALRRIIALLLKNPDATAFLNSP\n",
      "^MSVLELHWRYEKTSGSLANLIQLELDAKLEGMLDLEERLGELAELARRALGKLKAMDALVKKGCADLCRILKAQGNSEEKREEALIILMPKNDLKPNKAKERLLAILILRAAILLTHRDKIVLDWIIRTIALGLAKAAKSRKEQLGYAACRDIKGKVYYGGCVLGYKAAITLMISNAQGILPVAAKSARPWDLVAATI$\n",
      "^MANWIRSKLANNLYMVGKVIILSPKKLQAMLTEPTARDSPGFCSSCLLQKIHEAIEEHPLASLTLELECLHQKKKMLCAKDEILAVTALKRPLQECYKFSGDSLKKGWDNLLAYPYLLNEKLTLSESRNQKLPEQIAAEAEIGKIYAGSIYVDPKILAKLVLPKIKPRKLAKAVILIELEELYENSVLASPQSASAKAN\n",
      "^MMTGGRLLVEDADLPSLGVCHGAHVVDELALRCRYVEGELQAARAGLLQLLLALGNLTALATLSTELAPCLERQQNDEDQIKELERCADYEGKIILLGRVILAPLAASAKQRACTLARTYLLASPGAYMAVIAGLCALCRYDKERAAFRIHLLPCGMDAIHADTSALGLLRPALQDAPAHMCLTSKGVRHEFCCGAESG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5082/5082 [06:24<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^MRWTLSVIGKALVIWHIQGVVAPESPGMAVNLKKITEIAGQSYNVYIDEVQGKLVNPLSECRRSPGIVKLLGVEETIHPSLAKRAFSSKEYRLDDYISPVLVEECGEFRSRSIYLMPREHYLSSGDVYAGPALEGMLWGQILILENVMGFRASIGEGLAEVAFCSLHVGHLSERPVAEGKIKVCKHSIKLSQGPAGLA$\n",
      "^MAICKECKEVPGICGSQKGLIWGRLKLLAESEAVLKVSIKSITEPRFSGRRMRSSMAEINETIDSGYILRINIPPMILIERAIKTSIEEILGHGALAVHRCGEVEIEGEGQFLVHAPLTSGKVEVILRGVSEGKGLAVQMHAYLRARESYFEVFYEGIKCLFILGSKREQAGCTRICTPEDKRTKIVRVSKPEHPGKT$\n",
      "^MAEYLLLAEQIVKRTWLDLVGVTTRYAIAIDNIVEVQSTKFYRKIALPEKVYVMILNNSDAVVFNLELTRLKVDARPLIPYCISVTTFTGVILDQGSAPEDAAKRAAAAIVALIDTAKGREPYGVPLEIIATWFRMAKDAAKQGSLRYLPDISEMLVYATGCSNRFIAERLSAGMHYNPQSIPEKIKNRQSLIHPQQK$\n",
      "^MSCSTVERRSELIWKKVKEKEPARREIATFQLAPALGGPTCVFPPQVSTLGVAVGEIEIVPGWSGYDYPKYILAETKMPARWGVDKFLRFLKLETAPPTAHAMCGVNYIKSERAAILKREKREDLVPVIEAFLNTSRTAMLERLSVLMILVPESPARCAYPISTTMIVLIEGKICIICYGQQLIAGKLLYGREKKHSQ$\n",
      "^MRISDCLGYPKLVIAAIIDSMQKEVSSGLWRTFVAPPAKGPLACPSPCFAVAAYRFHDGTLKHVSAKEMLSDQIDVISFQGGQEVTIGARISVIWGMPVERYCKPAKVFIGSIKTRGRDFVSMGERTLYSETTILNEIVGQTMQVLHSLGPERMSPAIRSYNEDEGISIPAEIEPQSLIRTSPHEFGPRASSLLNELS$\n",
      "^MKIEDEIKRLAEFLIGIKAILKAIEISVNQMIILGRYEVTILWAKPRSHELKAAHDAAKYLIAPGEKRAIISEGPEAVEVILQNIIPEIDRKLVLEAVTAISGLANLGLFSIQIQIVEIYSKAPSGGDGKADEVGKAILEEAMEIDLIKAYAEVGIYPFARAKDGEHKAPIIEGTNLNLEVPIEDLRALPEKLIKAAH$\n",
      "^MAPWASLSSLKLYSMNLQESWDKANIPNILKKASSALWIAENKVCCFEVGGSLRAFISREGCNMVVGINVDYLPECQKGEATAAKRGRMEEVQRVLFMSINFYTIGLEYARGSGCIKIAQVEVGKGMVIMAGCDACGIKGHDATAVKIEAPELRRGGTYFTINITCEITGAVVLPPSACLLKERPESLKGHLEALPEH$\n",
      "^MEMKLACSEIRDRMHKGLKAKLESUDGLPAPIIIARSPFCEGVDIKEIALQDAVPTREIVPFAIYAELCTLPGIAYSGGLIWLRRELNERGVCVLAVTFSTIEVCELLRVYFPSEERGVGLEGPEAGTAHPKAICWELSIPELAAEMLLLGLPIGIYQGKAMKLKGKGIIVCECGEASLGPHTAKLKIELDKVLLLQIP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5082/5082 [06:02<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^MSSNSKLKYRLPGHLAIMSRDKNALNVLAVVKLNWLLRARAKQAVLSVCEITEVLATLVGGMLFLLDLIDSNELSRVFHRLVRVIPHLMTGTSQRNFYLLDADVMLLMGLGAMAGRVLLMLVVTFGRKSSNPQWQWYPSPHRGGIAISCEFETLFANGGVDGQFGIAKRGESTCTISASSAGFLQSCQRKEERQTYK$$\n",
      "^MAWSVVDIFLGCEGGSGLGMTDAVGGGYAVAIMLCIGIIKIMQPPRKKQQEWTKYEVGFAVSVTIELGLQARPVKVLVTPGIKAPKTCEAKRKVPMPDSVFIPDATPENIERHDYTNVSFAHEMCEHQFHSFRKGQTTIPSAISNAKEDCFTWLKGEGINEATASAGEMQAKVDTEALACRGSLHVPQGPEERSLKRH$\n",
      "^MKNLLVLTARHAYLPASWVTAIVSNLADLACMKAETKQECRVTVKPMGLCSEVPTMQKATTECHVEPEDQQAAQREQGTCTASADRVCSFLEEKSDLVRSTSLTPTCGIWPGGQIPMTYEAMLVHHLIGHLPCRQKTKQSPKEELLMPEQGCITCNDHMRLFHAELTSCACLERGTKTKEEGCKHGAEVPAVLLLKA$$\n",
      "^MKYRECGTVKYSDRSRCLLYLVHCGLTTRATGTIVSAHRCRASETICGCAKVKRGCFSLEKKRKKPRTCCFFADGRTVTCELEIRREQSHPHCKYFHDSDWHLVIWRSCQEGACGRCAMCTALPPGKLKTSGPIAVPRWEGCAKPRKYKEELGCVFCMSTARLKHSSWQEMRLYTEISTFARGAAQVGIPECGFLHLH$\n",
      "^MTEAIELITEGVTYDIAKQRKNKALLEIAQVGLKILTTTMVTIVIRAKILAEEIQQPVQNFHQIKAHTSDLRLLTGRFSSAGLCCCGAHETQDALLGAEDSAEYLKAKKMWYKCMDCTLTSPSAAPAIDTHQIREIGSVCYDDEGGTSFDRAGTLALMKLIAERMNPFTGTPNKKNDEPVEVTNSEPSQHANKLQGSW$\n",
      "^MRLVRKTVPMILGATTVQKLVTPGVEWTIAAWRGVSKLERDLIESKSWMTPPKYRVNSKLSLNACMGAMARGTVLGSVDQCTLSRDIIKASFLLLSLMGCGCVEESEQKETWETQDKGSTRLIETLSLEDRHGYFSLLFYFSNQSDFDWLQMETSYDHMCAGKAKGCKAEMIAGFTADQKSGDWSMQFLEQGIDLNF$G\n",
      "^MVSQQTKNRRIVQCMSGLAQREATDLAGGTNGWSADCILEAGHVWQTCMRHRRCTFMLATARPEVTLLQCRNDINVKQNGLTPAFKWCLLQMITQITVGTDNLMGYDQVQRALAQCTSHKMARSAQKLWGHIAKAKEGRIIIILIDCSRGKILMIGSKVIEVEWSLAGEELDLGGRPAAKGRGYRLYLDTMTGHLERI$\n",
      "^MTGGKGGKSRKKMSGGMKPNLEMCGAVLAGFRGAEKADWAARRQGSLIVVYLTGMQEQLKMVESGKTGKIICIVGAGLFLDEHYVPPARLESLVHEFVFVQRTVMGMDKQETKKATLESSAVEARCQAQNYHLAKPILMASYTQERQQFTCQEMQTILKGLYGQDMWLYRRQHTDGVALSSELLLAAEDCPRHIPALAK\n"
     ]
    }
   ],
   "source": [
    "train_loss = 0.\n",
    "has_nan_log = 0\n",
    "nan_count = 0\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# def _save_output(module, grad_input, grad_output):\n",
    "#     print(module, grad_output)\n",
    "#     print(torch.isnan(grad_output[0]).any())\n",
    "#     print()\n",
    "\n",
    "# for name, module in model.named_modules():\n",
    "#     if str(type(module)).find(\"LayerNorm\") != -1:\n",
    "#         print(name)\n",
    "#         module.register_full_backward_hook(_save_output)\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        run.log({\"epoch\": epoch, \"minibatch\": i}, commit=False)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        diffusion_t = diffusion_instance.sample_t()\n",
    "        # print(diffusion_t)\n",
    "\n",
    "        metrics = mask_diffusion.compute_kl_reverse_process(\n",
    "            batch[\"input_ids\"].to(args.device),\n",
    "            diffusion_t,\n",
    "            denoise_fn=denoise_fn,\n",
    "            diffusion=diffusion_instance,\n",
    "            target_mask=batch[\"attention_mask\"].to(args.device),\n",
    "            hybrid_lambda=args.hybrid_lambda,\n",
    "            predict_x0=True, # False,\n",
    "            word_freq_logits=batch[\"word_freq_logits\"].to(args.device),\n",
    "            device=args.device\n",
    "        )\n",
    "\n",
    "        # print(metrics)\n",
    "\n",
    "        loss = metrics[\"loss\"] / args.batch_size / batch[\"input_ids\"].size(1)\n",
    "\n",
    "        if loss.isnan():\n",
    "            nan_count += 1\n",
    "            if i % args.logging_steps == args.logging_steps - 1:\n",
    "                run.log({\"nan_count\": nan_count})\n",
    "            continue\n",
    "            \n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        if args.clip_grad:\n",
    "            torch.nn.utils.clip_grad_value_(trainable_params, args.clip_grad_val)\n",
    "        \n",
    "        has_nan = 0\n",
    "        for param in trainable_params:\n",
    "            if param.grad is not None:\n",
    "                if torch.isnan(param.grad).any():\n",
    "                    param.grad = torch.nan_to_num(param.grad, nan=0.0)\n",
    "                    has_nan = 1\n",
    "\n",
    "        has_nan_log += has_nan\n",
    "        \n",
    "        optimizer.step()\n",
    "        if args.warmup_scheduler:\n",
    "            warmup_scheduler.step()\n",
    "\n",
    "        if i % args.logging_steps == args.logging_steps - 1:\n",
    "            run.log(metrics, commit=False)\n",
    "            if args.warmup_scheduler:\n",
    "                run.log({\"last_lr\": warmup_scheduler.get_last_lr()}, commit=False)\n",
    "            run.log({\"nan_count\": nan_count, \"nan -> zero\": has_nan_log})\n",
    "            has_nan_log = 0\n",
    "\n",
    "    # generate some proteins\n",
    "    generated = mask_diffusion.discrete_diffusion_predict_fn((8, 200), denoise_fn, diffusion_instance, topp=1.0)\n",
    "    generated_table = wandb.Table(columns=[\"gen_id\", \"seq\"])\n",
    "    for j, genseq in enumerate(generated[\"final_state\"].tolist()):\n",
    "        genprot = tokenizer.untokenize(genseq)\n",
    "        generated_table.add_data(j, genprot)\n",
    "        print(genprot)\n",
    "    run.log({\"generated_proteins\": generated_table})\n",
    "\n",
    "    torch.save(model.state_dict(), f\"../checkpoints/{run.name}-postepoch-{epoch}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54c63062-03b8-404c-858b-a0c7c2753c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^MKEDVLVVQGGALRASIPVREKAGLNKTTTCDLGSTKSGQLLCVIAHNKELSTYEHPSSTPHRPKISCYSAEKHSCLLSHPTAKQWCCPHGGPSSTKSD\n"
     ]
    }
   ],
   "source": [
    "generated = mask_diffusion.discrete_diffusion_predict_fn((1, 100), denoise_fn, diffusion_instance, topp=1.0)\n",
    "for g in generated[\"final_state\"].tolist():\n",
    "    print(tokenizer.untokenize(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c50bad-3ef8-4a5d-89a8-00bfd26d00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), f\"../checkpoints/{run.name}-postepoch-{epoch}-optimizer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662719d9-fadf-4478-8209-2874c6a3b001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
