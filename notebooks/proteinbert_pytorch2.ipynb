{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7facdc65-6ab7-461e-bba1-7cce60eba128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/dohlee/proteinbert-pytorch/blob/master/proteinbert_pytorch/proteinbert_pytorch.py\n",
    "# from https://gist.github.com/chirag1992m/4c1f2cb27d7c138a4dc76aeddfe940c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a75f1a-2553-47c4-a874-62c3114b7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f4a23b-92d1-47cd-a5b8-f53e99d94ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch import einsum\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "    \n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=9, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv_narrow = nn.Sequential(\n",
    "            Rearrange('b l d -> b d l'),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding='same', dilation=1),\n",
    "            nn.GELU(),\n",
    "            Rearrange('b d l -> b l d')\n",
    "        )\n",
    "        self.conv_wide = nn.Sequential(\n",
    "            Rearrange('b l d -> b d l'),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding='same', dilation=5),\n",
    "            nn.GELU(),\n",
    "            Rearrange('b d l -> b l d')\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv_narrow(x) + self.conv_wide(x)\n",
    "\n",
    "class GlobalAttention(nn.Module):\n",
    "    def __init__(self, d_local, d_global, n_heads, d_key):\n",
    "        super().__init__()\n",
    "        d_value = d_global // n_heads\n",
    "\n",
    "        self.to_q = nn.Sequential(\n",
    "            nn.Linear(d_global, d_key * n_heads, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.to_k = nn.Sequential(\n",
    "            nn.Linear(d_local, d_key * n_heads, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.to_v = nn.Sequential(\n",
    "            nn.Linear(d_local, d_value * n_heads, bias=False),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "        self.d_key = d_key\n",
    "    \n",
    "    def forward(self, x_local, x_global):\n",
    "        q = self.to_q(x_global)\n",
    "        k = self.to_k(x_local)\n",
    "        v = self.to_v(x_local)\n",
    "\n",
    "        q = rearrange(q, 'b (h d) -> b h d', h=self.n_heads)\n",
    "        k = rearrange(k, 'b l (h d) -> b l h d', h=self.n_heads)\n",
    "        v = rearrange(v, 'b l (h d) -> b l h d', h=self.n_heads)\n",
    "\n",
    "        att = einsum('b h d, b l h d -> b h l', q, k) / math.sqrt(self.d_key)\n",
    "        att = att.softmax(dim=-1)\n",
    "\n",
    "        x_global = einsum('b h l, b l h d -> b h d', att, v)\n",
    "        x_global = rearrange(x_global, 'b h d -> b (h d)')\n",
    "        return x_global\n",
    "\n",
    "\n",
    "class TransformerLikeBlock(nn.Module):\n",
    "    def __init__(self, d_local, d_global):\n",
    "        super().__init__()\n",
    "\n",
    "        self.wide_and_narrow_conv1d = ConvBlock(d_local, d_local)\n",
    "        self.dense_and_broadcast = nn.Sequential(\n",
    "            nn.Linear(d_global, d_local),\n",
    "            nn.GELU(),\n",
    "            Rearrange('b d -> b () d')\n",
    "        )\n",
    "        self.local_ln1 = nn.LayerNorm(d_local)\n",
    "        self.local_dense = nn.Sequential(\n",
    "            Residual(nn.Sequential(nn.Linear(d_local, d_local), nn.GELU())),\n",
    "            nn.LayerNorm(d_local),\n",
    "        )\n",
    "\n",
    "        self.global_dense1 = nn.Sequential(nn.Linear(d_global, d_global), nn.GELU())\n",
    "        self.global_attention = GlobalAttention(d_local, d_global, n_heads=4, d_key=64)\n",
    "        self.global_ln1 = nn.LayerNorm(d_global)\n",
    "        self.global_dense2 = nn.Sequential(\n",
    "            Residual(nn.Sequential(nn.Linear(d_global, d_global), nn.GELU())),\n",
    "            nn.LayerNorm(d_global),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_local, x_global):\n",
    "        x_local = self.local_ln1(\n",
    "            x_local + self.wide_and_narrow_conv1d(x_local) + self.dense_and_broadcast(x_global)\n",
    "        )\n",
    "        x_local = self.local_dense(x_local)\n",
    "\n",
    "        x_global = self.global_ln1(\n",
    "            x_global + self.global_dense1(x_global) + self.global_attention(x_local, x_global)\n",
    "        )\n",
    "        x_global = self.global_dense2(x_global)\n",
    "\n",
    "        return x_local, x_global\n",
    "\n",
    "class ProteinBERT(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size,\n",
    "            ann_size,\n",
    "            d_local=128,\n",
    "            d_global=512,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_local = nn.Embedding(vocab_size, d_local)\n",
    "        self.embed_global = nn.Sequential(nn.Linear(ann_size, d_global), nn.GELU())\n",
    "\n",
    "        self.blocks = nn.ModuleList([TransformerLikeBlock(d_local, d_global) for _ in range(6)])\n",
    "\n",
    "        self.local_head = nn.Sequential(nn.Linear(d_local, vocab_size))  # NOTE: logits are returned\n",
    "        self.global_head = nn.Sequential(nn.Linear(d_global, ann_size), nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, x_local, x_global):\n",
    "        x_local = self.embed_local(x_local)\n",
    "        x_global = self.embed_global(x_global)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x_local, x_global = block(x_local, x_global)\n",
    "\n",
    "        return self.local_head(x_local), self.global_head(x_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd39b909-2808-4f40-9b2a-39bc8112f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_weights(model, weights):\n",
    "    # reorganize weights\n",
    "    for i, weight in enumerate(pretrained_model_weights):\n",
    "        if i == 2:\n",
    "            continue\n",
    "        if len(weight.shape) == 2:\n",
    "            pretrained_model_weights[i] = np.transpose(weight, (1, 0))\n",
    "            continue\n",
    "        \n",
    "        if (3 <= i <= 140):\n",
    "            if i % 23 == 17:\n",
    "                pretrained_model_weights[i] = np.transpose(weight, (0, 2, 1)).reshape(4 * 64, 512)\n",
    "                continue\n",
    "            if i % 23 == 18:\n",
    "                pretrained_model_weights[i] = np.transpose(weight, (0, 2, 1)).reshape(4 * 64, 128)\n",
    "                continue\n",
    "            if i % 23 == 19:\n",
    "                pretrained_model_weights[i] = np.transpose(weight, (0, 2, 1)).reshape(4 * 128, 128)\n",
    "                continue\n",
    "    \n",
    "        if len(weight.shape) == 3:\n",
    "            pretrained_model_weights[i] = np.transpose(weight, (2, 1, 0))\n",
    "\n",
    "    # convert all to tensors\n",
    "    for i, weight in enumerate(pretrained_model_weights):\n",
    "        pretrained_model_weights[i] = torch.from_numpy(weight)\n",
    "        \n",
    "    # load weights\n",
    "    state = model.state_dict()\n",
    "    state[\"embed_local.weight\"] = pretrained_model_weights[2]\n",
    "    state[\"embed_global.0.weight\"] = pretrained_model_weights[0]\n",
    "    state[\"embed_global.0.bias\"] = pretrained_model_weights[1]\n",
    "    \n",
    "    for block in range(6):\n",
    "        idx = 3 + block * 23\n",
    "        state[f\"blocks.{block}.wide_and_narrow_conv1d.conv_narrow.1.weight\"] = pretrained_model_weights[idx + 2]\n",
    "        state[f\"blocks.{block}.wide_and_narrow_conv1d.conv_narrow.1.bias\"] = pretrained_model_weights[idx + 3]\n",
    "        state[f\"blocks.{block}.wide_and_narrow_conv1d.conv_wide.1.weight\"] = pretrained_model_weights[idx + 4]\n",
    "        state[f\"blocks.{block}.wide_and_narrow_conv1d.conv_wide.1.bias\"] = pretrained_model_weights[idx + 5]\n",
    "        state[f\"blocks.{block}.dense_and_broadcast.0.weight\"] = pretrained_model_weights[idx]\n",
    "        state[f\"blocks.{block}.dense_and_broadcast.0.bias\"] = pretrained_model_weights[idx + 1]\n",
    "        state[f\"blocks.{block}.local_ln1.weight\"] = pretrained_model_weights[idx + 6]\n",
    "        state[f\"blocks.{block}.local_ln1.bias\"] = pretrained_model_weights[idx + 7]\n",
    "        state[f\"blocks.{block}.local_dense.0.fn.0.weight\"] = pretrained_model_weights[idx + 8]\n",
    "        state[f\"blocks.{block}.local_dense.0.fn.0.bias\"] = pretrained_model_weights[idx + 9]\n",
    "        state[f\"blocks.{block}.local_dense.1.weight\"] = pretrained_model_weights[idx + 10]\n",
    "        state[f\"blocks.{block}.local_dense.1.bias\"] = pretrained_model_weights[idx + 11]\n",
    "        state[f\"blocks.{block}.global_dense1.0.weight\"] = pretrained_model_weights[idx + 12]\n",
    "        state[f\"blocks.{block}.global_dense1.0.bias\"] = pretrained_model_weights[idx + 13]\n",
    "        state[f\"blocks.{block}.global_attention.to_q.0.weight\"] = pretrained_model_weights[idx + 14]\n",
    "        state[f\"blocks.{block}.global_attention.to_k.0.weight\"] = pretrained_model_weights[idx + 15]\n",
    "        state[f\"blocks.{block}.global_attention.to_v.0.weight\"] = pretrained_model_weights[idx + 16]\n",
    "        state[f\"blocks.{block}.global_ln1.weight\"] = pretrained_model_weights[idx + 17]\n",
    "        state[f\"blocks.{block}.global_ln1.bias\"] = pretrained_model_weights[idx + 18]\n",
    "        state[f\"blocks.{block}.global_dense2.0.fn.0.weight\"] = pretrained_model_weights[idx + 19]\n",
    "        state[f\"blocks.{block}.global_dense2.0.fn.0.bias\"] = pretrained_model_weights[idx + 20]\n",
    "        state[f\"blocks.{block}.global_dense2.1.weight\"] = pretrained_model_weights[idx + 21]\n",
    "        state[f\"blocks.{block}.global_dense2.1.bias\"] = pretrained_model_weights[idx + 22]\n",
    "\n",
    "    state[\"local_head.0.weight\"] = pretrained_model_weights[141]\n",
    "    state[\"local_head.0.bias\"] = pretrained_model_weights[142]\n",
    "    state[\"global_head.0.weight\"] = pretrained_model_weights[143]\n",
    "    state[\"global_head.0.bias\"] = pretrained_model_weights[144]\n",
    "\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "with open(\"../weights/epoch_92400_sample_23500000.pkl\", \"rb\") as f:\n",
    "    n_annotations, pretrained_model_weights, pretrained_optimizer_weights = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6d095dc-833c-4ffa-9d30-1e0591b4be80",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m bsz \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m ProteinBERT(vocab_size, ann_size)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mload_pretrained_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m x_local \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, vocab_size, (bsz, \u001b[38;5;241m52\u001b[39m))\n\u001b[1;32m      9\u001b[0m x_global \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(bsz, ann_size)\n",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m, in \u001b[0;36mload_pretrained_weights\u001b[0;34m(model, weights)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# convert all to tensors\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pretrained_model_weights):\n\u001b[0;32m---> 26\u001b[0m     pretrained_model_weights[i] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# load weights\u001b[39;00m\n\u001b[1;32m     29\u001b[0m state \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "vocab_size = 26\n",
    "ann_size = 8943\n",
    "bsz = 1\n",
    "\n",
    "model = ProteinBERT(vocab_size, ann_size)\n",
    "load_pretrained_weights(model, pretrained_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ef9b96c-4e79-4470-bc0a-b2aacd1014b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 52, 26]) torch.Size([1, 8943])\n",
      "15981321\n"
     ]
    }
   ],
   "source": [
    "x_local = torch.randint(0, vocab_size, (bsz, 52))\n",
    "x_global = torch.rand(bsz, ann_size)\n",
    "\n",
    "x_local, x_global = model(x_local, x_global)\n",
    "print(x_local.shape, x_global.shape)\n",
    "\n",
    "# Print the number of parameters in the model.\n",
    "# NOTE: Must have ~16M parameters according to the paper.\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47ea62-bfb5-488c-aa2e-e2c13adfb930",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_AAS = 'ACDEFGHIKLMNPQRSTUVWXY'\n",
    "ADDITIONAL_TOKENS = ['<OTHER>', '<START>', '<END>', '<PAD>']\n",
    "\n",
    "# Each sequence is added <START> and <END> tokens\n",
    "ADDED_TOKENS_PER_SEQ = 2\n",
    "\n",
    "n_aas = len(ALL_AAS)\n",
    "aa_to_token_index = {aa: i for i, aa in enumerate(ALL_AAS)}\n",
    "additional_token_to_index = {token: i + n_aas for i, token in enumerate(ADDITIONAL_TOKENS)}\n",
    "token_to_index = {**aa_to_token_index, **additional_token_to_index}\n",
    "index_to_token = {index: token for token, index in token_to_index.items()}\n",
    "n_tokens = len(token_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21282726-97a9-4c7f-af8b-20174a451991",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEncoder:\n",
    "    def __init__(self, n_annotations):\n",
    "        self.n_annotations = n_annotations\n",
    "\n",
    "    def parse_seq(self, seq):\n",
    "        if isinstance(seq, str):\n",
    "            return seq\n",
    "        elif isinstance(seq, bytes):\n",
    "            return seq.decode('utf8')\n",
    "        else:\n",
    "            raise TypeError('Unexpected sequence type: %s' % type(seq))\n",
    "        \n",
    "    def tokenize_seq(self, seq):\n",
    "        other_token_index = additional_token_to_index['<OTHER>']\n",
    "        return [additional_token_to_index['<START>']] + \\\n",
    "            [aa_to_token_index.get(aa, other_token_index) for aa in self.parse_seq(seq)] + \\\n",
    "            [additional_token_to_index['<END>']]\n",
    "    \n",
    "    def tokenize_seqs(self, seqs, seq_len):\n",
    "        # Note that tokenize_seq already adds <START> and <END> tokens.\n",
    "        return np.array(\n",
    "            [\n",
    "                seq_tokens + (seq_len - len(seq_tokens)) * [additional_token_to_index['<PAD>']]\n",
    "                for seq_tokens in map(self.tokenize_seq, seqs)\n",
    "            ],\n",
    "            dtype = np.int32\n",
    "            )\n",
    "    \n",
    "    def encode_X(self, seqs, seq_len):\n",
    "        return [\n",
    "            self.tokenize_seqs(seqs, seq_len),\n",
    "            np.zeros((len(seqs), self.n_annotations), dtype = np.int8)\n",
    "        ]\n",
    "\n",
    "    def decode_output(self, pred):\n",
    "        pred = torch.argmax(pred, 2)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7361b63-9dec-4cbc-a096-36f0bd181839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_str(pred):\n",
    "    idx_to_tok = list(\"ACDEFGHIKLMNPQRSTUVWXY?^$_\")\n",
    "    ret = []\n",
    "    for i in pred:\n",
    "        out = \"\".join([idx_to_tok[j] for j in i])\n",
    "        ret.append(out)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903a165-5712-4a6a-9e98-821dee583f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_enc = InputEncoder(n_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffcd0c4-10c0-46bc-a9c2-86d31b538be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prots = {\n",
    "    \"test\": \"XLGMIRNSLFGSVETWPWQVLSTGGKEDVSYEERACEGGKFATVEVTDKPVDEALREAMPKIMKYVGGTN\",\n",
    "    \"insulin_correct\": \"MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGERGFFYTPKTRREAEDLQVGQVELGGGPGAGSLQPLALEGSLQKRGIVEQCCTSICSLYQLENYCN\",\n",
    "    \"chained\": \"YRGDXXXRGDXXXRGDXXXRGDXXXRGD\"\n",
    "}\n",
    "\n",
    "prot_seqs = []\n",
    "for name, seq in prots.items():\n",
    "    seq_tok, global_anno = input_enc.encode_X([seq], 200)\n",
    "    seq_tok = torch.from_numpy(seq_tok).long()\n",
    "    global_anno = torch.from_numpy(global_anno).float()\n",
    "    pred_local, pred_global = model(seq_tok, global_anno)\n",
    "    print(name)\n",
    "    print(pred_to_str(input_enc.decode_output(pred_local))[0])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013938d-d261-4c15-b710-18a9b1541b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6694535-ac3e-4db6-bf24-873bbe6ff15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e937c71-edf5-47dc-9a4c-0e4a488d4695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
